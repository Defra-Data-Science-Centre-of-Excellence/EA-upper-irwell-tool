{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a540ff53-9720-4d9f-8137-6ad484976a59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "chnkTsDL44gb"
   },
   "source": [
    "\n",
    "# Upper Irwell Investment tool\n",
    "\n",
    "Welcome to the Upper Irwell Investment tool. This workbook will take you step by step through the process of identifying priority areas of investment in NFM schemes based on existing data that the EA holds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f313e44-869a-41fb-b135-dbf8a805434a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "pdGu6dwSnfbU"
   },
   "source": [
    "\n",
    "# 1. Introduction\n",
    "This workbook is a unified workflow that combines the data and functionalities of four existing EA owned tools:\n",
    "\n",
    "1.\tNFM Opportunities Map (by JBA Consultants): Identifies areas capable of storing different water volumes and lists potential features for flood mitigation.\n",
    "2.\tNFM Storage Tool (by Jacobs): Analyzes how varying storage volumes affect flood hydrographs, return periods, and properties at risk.\n",
    "3.\tEA Property reports for all the communities at risk from the NW Opportunities Map/Toolkit (Jacobs) identifies numbers of properties at risk by risk band and deprivation, and weighted annual average damages. Also has lots of natural capital information. This is a GMMC only held data set.\n",
    "4.\tDEFRA Funding Calculator: Calculates potential funding released by DEFRA for flood mitigation schemes based on changes in property risk levels.\n",
    "\n",
    "It is important to note that this workbook is solely trying to make the best use of exisitng data and information. It should only be used as a scoping tool rather than as a detailed planning tool. Many assumptions and approximations are made throughout this workbook to be able to make this workflow. These are highlighted throughout the workbook.\n",
    "\n",
    "## How to use this workbook\n",
    "The Upper Irwell Investment tool consists of python code presented in a jupyter workbook, and a folder of data files associated with it. Rather than hiding the code away behind a user interface, it is presented here so that tool can be easily developed in the future.\n",
    "\n",
    "This is the master copy of the code and no one can edit it, so don't worry about making mistakes. To edit this document you must click file -> save a copy in drive and then edit that document instead. (you will need a google account to do this)\n",
    "\n",
    "### Uploading the data\n",
    "Go to the sharepoint site and download the folder 'Irwell_Tool_Data'. This contains all of the files you need to run the workbook. If this has downloaded as a zip file, make sure you unzip it to be able to access all of the files inside. Now go back to the google workbook and click on the folder symbol to the left of this text in colab. A sidebar should appear. Either drag and drop all of the files into the sidebar, or click the upload file symbol at the top and navigate to the files to upload. Some of the files are quite large, so make sure they have all uploaded properly before you run the workbook. You can see the progress of the uploads with a loading circle in the sidebar. Colab does not save this data, so you will need to upload it every session. Remeber to upload data to the main folder NOT the sample data folder.\n",
    "\n",
    "### Downloading the Results\n",
    "Results are stored in a folder called 'Results'. Make sure that you download files and save them to you own computer as they will be deleted from the colab storage when you close the workbook (or if you let the session expire). Navigate to the files you want to download then click the 3 dots next to the file and selevt download. Find the files you downloaded and rename/move them in accordance with your own naming conventions and file system. I have included the time and date that the file was created in the file name so that none of your results are overwritten. You need to rename them so they make sense to you!\n",
    "\n",
    "### What is python code?\n",
    "Do not be intimidated by the code!! Coding is just writing instructions in the correct language (python) and instructing the installed interpreter (python) to run the program on your computer. Rather than having to install python onto your computer, we will be working in google colab to avoid any intallation issues. Colab is basically letting us run python code on their servers in the cloud rather than running python on our own machine. This is why we need to upload any data that we want python to look at to the cloud.\n",
    "\n",
    "We are working in what is known as a 'Jupyter notebook' which lets us develop our code in a very interactive way, allowing us to have text, images, figures and code all in one place. You will see alternating text blocks and code blocks throughout this notebook. When code blocks are executed, graphs, text or data tables may be outputted beneath them.\n",
    "\n",
    "Ultimately, we are just writing instructions and getting a computer to interpret them. There are very few lines of code that you need to change in this workbook and they will be clearly marked with comments in the code. A python comment looks like this:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "# This is what a comment looks like. Anything that follows a hash symbol is ignored by python, so we can write human readable instructions directly into code blocks.\n",
    "```\n",
    "\n",
    "### Running the code\n",
    "Once you have made your changes to the code and have uploaded the associated dataset, you can execute the whole workbook by going to 'Runtime -> Run all' at the top of the page. This will run all of the code cells in the workbook. Note that 'optimisation' cells towards the end of the notebook may take a very long time (hours) to run. You may therefore wish to execute single cells of code instead. You can do so by pressing the 'play' button at the top left of a code cell.\n",
    "\n",
    "Note: Python works by running instructions in order. In the code we create data objects and variables that are held in the computer's memory. If we run a code cell again with different values, the variables will be overwritten in the memory of the computer with these new values. So if you start running cells out of order, then you may get some confusing results or some errors.\n",
    "\n",
    "### Errors\n",
    "When python can't understand something, it will create an error message beneath the code cell. These errors can be quite hard to interpret, even if you are familiar with python. Given how few lines of code there are to edit, it is unlikely that you will get any errors. The most likely ones that you will come across will because:\n",
    "- The data files have not uploaded correctly. Some of the files are big and if there is any disruption to the upload then they may be only partially there. Try again!\n",
    "- Typos. Code is VERY strict about characters, spaces, capitilization and punctuation. Check that everything is typed correctly then try again!\n",
    "- Searching for something that doesn't exist. It may be that a catchment or community that we thought was captured in the data isn't. You can check this by looking in the uploaded data files.\n",
    "\n",
    "There is an AI function in colab that will help you understand the errors better. Alternatively, copy and paste your error into google and look for similar problems on Stack Overflow. This is exactly what professional programmers do!\n",
    "\n",
    "If you feel like you've broken the code beyond repair, you can always start over and make a new copy of this master version! Or email elizabeth.lewis-3@manchester.ac.uk\n",
    "\n",
    "### Learning to code\n",
    "If you would like to learn how to code from the very beginning I have given you access to my 'introduction to python' training workbooks for free here:\n",
    "\n",
    "https://colab.research.google.com/drive/1CYsvSjWnFX8pzZDxxKw71VLCZAEicMgY?usp=sharing\n",
    "\n",
    "https://colab.research.google.com/drive/1KPeFL5e6A5i27c2eBqim4nKb7i5nT4Lc?usp=sharing\n",
    "\n",
    "\n",
    "\n",
    "### Workbook structure\n",
    "\n",
    "1.   Introduction\n",
    "2.   Importing functionality\n",
    "3.   Reading in the NFM opportunities map data\n",
    "4.   Reading in the JACOBS storage tool data\n",
    "5.   Functionality for calculating changes to communities at risk\n",
    "6.   Calculating changes to an individual community\n",
    "7.   Calculating funding information for the whole of the Upper Irwell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94633be5-aceb-4134-b484-312b1474aafc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "3XqZfYUxlDfE"
   },
   "source": [
    "\n",
    "# 2. Importing functionality\n",
    "\n",
    "The code in this section imports additional python packages to help us work with map data, tables of data, produce interactive graphs and more.\n",
    "\n",
    "We also have our own bespoke module 'calculator.py' this is the DEFRA funding calculator rewritten as python code. As the code is quite lengthy, it written as it's own python package that we import into the workbook, rather than being shown in its entirety here. The calculator code can be easily edited if needed in a text editor such as notepad.\n",
    "\n",
    "None of the code will run without this cell being executed first. It only needs to be executed once per session and may take a few moments to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91bec19f-e16a-4703-a689-b1a3f85e67ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install folium openpyxl geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1625fe1-d8ce-436c-a005-62c3e3b2973b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8257326-a71b-4c52-aa3b-9d1a107cfae1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "G4i0jGAjPsPg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# working with numerical data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import openpyxl\n",
    "\n",
    "# working with spatial data\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Making graphs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import folium\n",
    "import branca.colormap as cm\n",
    "import matplotlib.cm as mpl_cm\n",
    "import matplotlib.colors as mpl_colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60bd88e2-080b-4b4c-ba63-70ab900464f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the current user \n",
    "user =  dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()\n",
    "\n",
    "# Create the user workspace path for the calculator module\n",
    "sys.path.append(f\"/Workspace/Users/{user}/EA-upper-irwell-tool\")\n",
    "\n",
    "import calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d61c826-1d46-46b7-abd0-3be4399e9711",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Setting source and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e2cd811-13f2-42c9-a27f-4d8277020bf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"/dbfs/mnt/lab/unrestricted/irwell_data\"\n",
    "\n",
    "results_path = f\"/Workspace/Users/{user}/EA-upper-irwell-tool/results\"\n",
    "\n",
    "if not os.path.exists(results_path):\n",
    "    os.makedirs(results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a77d8b0-57d7-4fdf-98a8-4bc5ce03ce07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "lyEuIw4558NH"
   },
   "source": [
    "# 3. Reading in the NFM opportunities map data\n",
    "\n",
    "The JBA Natural Flood Management (NFM) maps visualise the changes that NFM measures are predicted to have on surface water runoff, in terms of peak surface runoff reduction and timing of the peak runoff.\n",
    "\n",
    "Descriptions of the maps are found here: https://assets.publishing.service.gov.uk/media/6036c659d3bf7f0ab2f070c1/Working_with_natural_processes_mapping_technical_report.pdf It details how these numbers have been calculated.\n",
    "\n",
    "## Map attributes\n",
    "\n",
    "NFM features have been aggregated to the water body scale, which we use here from the file 'a0000002b.gdbtable'. The water body map contains the following attributes:\n",
    "\n",
    "- 'WB_NAME': Water body name\n",
    "- 'Headwater': River name\n",
    "- 'EA_WB_ID': Water body ID- EA assigned\n",
    "- 'JBA_CAT_ID': Water body ID- JBA assigned\n",
    "- 'Extra_Pond_Capacity_RP100_10': Additional potential storage based on a 100yr flood\n",
    "- 'Existing_Pond_Volume_RP100_10': Existing storage based on a 100yr flood\n",
    "- 'Area_km2': Water body area\n",
    "- 'Workshop_WfW_Area_km2': Woodlands for Water area, refined at stakeholder workshop\n",
    "- 'Workshop_ImpGrass_Area_km2': Improved grassland area, refined at stakeholder workshop\n",
    "- 'Workshop_Urban_Area_km2': Urban extent\n",
    "- 'Workshop_CombLoss_Area_km2': Area of improved soil structure, resulting in enhanced soil moisture storage capacity in rural areas and increased green spaces in urban areas\n",
    "- 'Losses_PercRed_RP30': Percent reduction in the 30yr flow due to enhanced rural and urban losses\n",
    "- 'WfW_PercRed_RP30': Percent reduction in the 30yr flow due to increased woodlands\n",
    "- 'RAF_PercRed_RP30': Percent reduction in the 30yr flow due to runoff attenuation features\n",
    "- 'Losses_PercRed_RP100: Percent reduction in the 100yr flow due to enhanced rural and urban losses\n",
    "- 'WfW_PercRed_RP100': Percent reduction in the 100yr flow due to increased woodlands\n",
    "- 'RAF_PercRed_RP100': Percent reduction in the 100yr flow due to runoff attenuation features\n",
    "- 'Base_ToP_RP30': Time of peak flow in the 30yr design event\n",
    "- 'Losses_ToP_RP30': Time of peak flow in the 30yr design event under enhanced rural and urban losses scenario\n",
    "- 'WfW_ToP_RP30': Time of peak flow in the 30yr design event under enahnced woodland scenario\n",
    "- 'RAF_ToP_RP30': Time of peak flow in the 30yr design event under enhanced runoff attenuation feature scenario\n",
    "- 'Base_ToP_RP100': Time of peak flow in the 100yr design event\n",
    "- 'Losses_ToP_RP100': Time of peak flow in the 100yr design event under enhanced rural and urban losses scenario\n",
    "- 'WfW_ToP_RP100': Time of peak flow in the 30yr design event under enahnced woodland scenario\n",
    "- 'RAF_ToP_RP100: Time of peak flow in the 30yr design event under enhanced runoff attenuation feature scenario\n",
    "\n",
    "## How can we use this data?\n",
    "\n",
    "Only the Runoff Attenuation Feature layer reports volumes of water stored. To use the other layers, we will need to approximate increased storage of water from increased area or improved soil/woodland:\n",
    "- Assuming a soil depth of 1m and an increase in 10% storage capacity of the soil, we can calculate a volume of water reatined by the NFM features.\n",
    "- 1km2 = 1000000m2,\n",
    "- with a depth of 1m, 1km2 = 1000000 m3 of soil\n",
    "- with an increase of 10% storage, 1km2 = 100000 m3 of water stored\n",
    "\n",
    "## Assumptions relating to the use of the NFM maps\n",
    "- Potential storage capacity is distributed evenly across the water body\n",
    "- Values relating to the 100yr simulations are reflective of the maximum storage capacity and are applicable at all return periods.\n",
    "- Equivalent storage can be approximated from land cover change scenarios\n",
    "- Storage from different NFM features can be stacked (i.e. added together to find a maximum potential storage)\n",
    "\n",
    "## Running the code\n",
    "\n",
    "The first line of code in this section can be changed to only include NFM types of interest. The relevant NFM features we can investigate are:\n",
    "\n",
    "- 'Extra_Pond_Capacity_RP100_10' Adding pond capacity\n",
    "- 'WfW' adding woodland\n",
    "- 'Losses' adding extra storage in rural and urban soil\n",
    "- 'ImpGrass' adding extra storage trough improving the storage capacity of soil in grassland\n",
    "\n",
    "If you want to explore all options combined use the following line of code:\n",
    "\n",
    "```\n",
    "NFM_features_to_include = ['Extra_Pond_Capacity_RP100_10', 'WfW', 'Losses', 'ImpGrass']\n",
    "```\n",
    "\n",
    "If you want to just look at using only certain NFM features, delete the names that are not of interest. For example, if you are only interested in adding ponds use the following line of code:\n",
    "\n",
    "```\n",
    "NFM_features_to_include = ['Extra_Pond_Capacity_RP100_10']\n",
    "```\n",
    "\n",
    "Or if you want to look at ponds and improved grassland use the following:\n",
    "\n",
    "```\n",
    "NFM_features_to_include = ['Extra_Pond_Capacity_RP100_10', 'ImpGrass']\n",
    "```\n",
    "Note that every aspect of punctuation is important. If you are missing a ' or , you will get an error!\n",
    "\n",
    "Nothing else in this section should be changed. Similar to section 1, the code in this section only needs to be run once per session to read in the NFM opportunities data. Reading data into memory is relatively slow, so it's better to avoid reading everything in again if you don't have to. If you change the NFM combination to explore, these code blocks should be executed again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be54a6b8-4072-4a26-8d1b-042b4f1d098a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "MX44KtSkPxDs"
   },
   "outputs": [],
   "source": [
    "# Select which NFM features to consider\n",
    "# The line of code below can be changed. Delete layers as applicable from the list [\"Extra_Pond_Capacity_RP100_10\", \"WfW\", \"Losses\", \"ImpGrass\"] below\n",
    "NFM_features_to_include = [\"Extra_Pond_Capacity_RP100_10\", \"WfW\", \"Losses\", \"ImpGrass\"]\n",
    "\n",
    "# Read in the NFM spatial data\n",
    "NFM_features_gdf = gpd.read_file(f\"{data_path}/a0000002b.gdbtable\")\n",
    "NFM_features_gdf[\"WfW\"] = NFM_features_gdf[\"Workshop_WfW_Area_km2\"]*10000\n",
    "NFM_features_gdf[\"Losses\"] = NFM_features_gdf[\"Workshop_CombLoss_Area_km2\"]*10000\n",
    "NFM_features_gdf[\"ImpGrass\"] = NFM_features_gdf[\"Workshop_ImpGrass_Area_km2\"]*10000\n",
    "NFM_features_gdf[\"total_NFM_storage\"] = NFM_features_gdf[NFM_features_to_include].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86cc8366-54c2-4ff1-8084-3b8291bfa7a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "iFjj1MTEVPC3"
   },
   "outputs": [],
   "source": [
    "# Read in the WFD water bodies shapefile\n",
    "wb_gdf = gpd.read_file(f\"{data_path}/WFD_Cycle_2_River_Water_Body_Catchments.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33b1f2cd-3e77-43bc-abfd-0452d2c958f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "d6Q1rJLFSBbk",
    "outputId": "dc6394dc-e4a9-40d9-89f0-fd340c8a59e7"
   },
   "outputs": [],
   "source": [
    "# Plot the NFM storage data and the WFD boundaries\n",
    "ax = NFM_features_gdf.plot(column=\"total_NFM_storage\", cmap=\"viridis\", legend=True, legend_kwds={\"label\":\"Total NFM storage (cubic m)\"})\n",
    "wb_gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"black\", linewidth=1, legend=True, legend_kwds={\"label\":\"WFD water bodies\", \"loc\": \"upper left\"})\n",
    "\n",
    "# Define a custom legend entry\n",
    "legend_elements = [Line2D([0], [0], color=\"black\", lw=1, label=\"WFD water bodies\")]\n",
    "ax.legend(handles=legend_elements, loc=\"upper left\")\n",
    "\n",
    "# Remove x and y ticks and labels to make the graph look neat\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ceeab14-5393-4517-b88c-4db4f79a91af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "SpqGYSZKZPqL"
   },
   "source": [
    "# 4. Reading in the JACOBS storage tool data\n",
    "\n",
    "The Jacobs NFM storage tool was developed to assess how much NFM storage is needed to reduce flood peaks in communities at risk. The tool uses the standard UK method for estimating flood flows (the Flood Estimation Handbook (FEH)) at 571 communities at Flood risk in the GMMC area. The tool calculates the volume of water that would be required to be stored upstream, to avoid flooding the downstream community at risk at different return period flows.\n",
    "\n",
    "## Tool attributes\n",
    "\n",
    "The underpinning dataset (Calculated_Hydrographs.csv) contains the following attributes:\n",
    "\n",
    "- 'Unique_id': Specific flow location just upstream of a community\n",
    "- 'SoP': standard of protection: indication of the lowest threshold of the risk for that community. Mising values == natural water courses, RP5 is default\n",
    "- 'RP': the RP for a given scenario\n",
    "- 'volume': proportion of hydrograph above the SoP threshold line, per timestep\n",
    "- 'QT': Flow at a specified timestep in the design even. measure in cubic meters per second\n",
    "- 'Flow': peak flow for a given RP\n",
    "\n",
    "\n",
    "## Assumptions relating to the use of the Jacobs tool\n",
    "- FEH method provides useful design hydrographs representative of the assigned return period.\n",
    "- A baseline standard of protection of RP5.\n",
    "- The properties at risk are at risk from river flooding based on the equivalent return period design storm from FEH.\n",
    "- Communities at risk that are situated at the confluence of two rivers combine the design hydrographs of both branches into a single set of hydrographs for use in the calculations.\n",
    "\n",
    "## Running the code\n",
    "\n",
    "Nothing in this section should be changed. Similar to section 1, the code in this section only needs to be run once per session to read in the JACOBS storage data data. Reading data into memory is relatively slow, so it's better to avoid reading everything in again if you don't have to. The JACOBS dataset is the largest file that has to be read into this workbook. I have therefore created a faster-to-load version of the file called 'Calculated_Hydrographs.p' which won't be human readable. If for some reason the JACOBS stoarage dataset 'Calculated_Hydrographs.csv' is ever changed, you can recreate this .p file by running the second code block below. To run it, first remove the triple quote marks at the start and end of the code. Create the .p file and download it manually from the files sidebar. Replace the original .p file in the files to upload folder and use that in the future . Replace the triple quotes when you are done.\n",
    "\n",
    "## Communities at Risk\n",
    "See below for the table of communities at risk and which design storm IDs are associated with them. If there are two IDs this means that the CaR sits at the confluence of two rivers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e43e4bac-5dc9-4ef3-891a-f5bf7c87a2af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "PwnW5WLaYiEu"
   },
   "outputs": [],
   "source": [
    "# Read in the communities at risk file names and associated Jacobs storage tool unique IDs\n",
    "CaR_ID_df = pd.read_csv(f\"{data_path}/CaR_name_ID.csv\")\n",
    "\n",
    "# Uploading the files to DBFS has replaced spaces and special characters with underscores, so when we\n",
    "# read the IDs file in we need to match the new filenames. \n",
    "CaR_ID_df[\"property_report_name\"] = (\n",
    "    CaR_ID_df[\"property_report_name\"]\n",
    "    .str.replace(\"&\", \"_\")  # Replace \"&\" with \"_\"\n",
    "    .str.replace(\" \", \"_\")  # Replace spaces with \"_\"\n",
    ")\n",
    "\n",
    "CaR_ID_df.head()\n",
    "a = CaR_ID_df.jacobs_storage_tool_ID.values\n",
    "CaR_IDs = []\n",
    "for i in a:\n",
    "  try:\n",
    "    CaR_IDs.append(int(i))\n",
    "  except:\n",
    "    j = [int(k) for k in i.split(\"/\")]\n",
    "    CaR_IDs.extend(j)\n",
    "\n",
    "CaR_IDs = list(set(CaR_IDs))\n",
    "CaR_ID_df.loc[:, [\"property_report_name\", \"jacobs_storage_tool_ID\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f919f7e-2b44-4464-ae44-31462651e2fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "id": "JAQlvYSsSCeu",
    "outputId": "552a20e0-84b5-4831-fe73-87c9845b934e"
   },
   "outputs": [],
   "source": [
    "# This code block creates the .p file from the .csv file. To run it, first remove the triple quote marks at the start and end of the code. Create the .p file and download it. Replace them when you are done.\n",
    "'''# Read in the Jacobs storage tool data (this stage is a bit slow because the file is large)\n",
    "NFM_storage = gpd.read_file('/content/Calculated_Hydrographs.csv')\n",
    "\n",
    "# Create a geometry column\n",
    "NFM_storage['geometry'] = NFM_storage.apply(lambda row: Point(row['SnappedX'], row['SnappedY']), axis=1)\n",
    "\n",
    "# Convert to GeoDataFrame and set CRS\n",
    "NFM_storage = gpd.GeoDataFrame(NFM_storage, geometry='geometry')\n",
    "NFM_storage.set_crs(epsg=27700, inplace=True)\n",
    "\n",
    "columns_to_int = ['Unique_ID']\n",
    "columns_to_float = ['Flow', 'timestep', 'QT']\n",
    "\n",
    "# Convert each column to int\n",
    "NFM_storage[columns_to_int] = NFM_storage[columns_to_int].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
    "NFM_storage[columns_to_float] = NFM_storage[columns_to_float].apply(pd.to_numeric, errors='coerce').fillna(0).astype(float)\n",
    "\n",
    "filehandler = open(\"Calculated_Hydrographs.p\",\"wb\")\n",
    "pickle.dump(NFM_storage, filehandler)\n",
    "filehandler.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3385333-1df5-4fe5-a23b-8e439f449f07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "T55ixYRuQ-Mm"
   },
   "outputs": [],
   "source": [
    "# Read in Jacobs storage tool pre-processed data\n",
    "file = open(f\"{data_path}/Calculated_Hydrographs.p\",\"rb\")\n",
    "NFM_storage = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab3953ea-f04f-47b1-80cf-b7a6fd901663",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "gso6u9jkXZZT"
   },
   "outputs": [],
   "source": [
    "# Find unique communities at risk in the Jacobs storage tool\n",
    "COR = NFM_storage.loc[(NFM_storage.RP == \"RP2\")&(NFM_storage.timestep == 0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5148561c-edef-478f-9674-aa942de27b6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "4QLPDHiPXVHQ",
    "outputId": "a9e08c94-0c0d-42ed-d4c1-6a99e6cb7883"
   },
   "outputs": [],
   "source": [
    "# Join the Jacobs and JBA data\n",
    "joined_gdf = gpd.sjoin(COR, NFM_features_gdf, how=\"inner\", predicate=\"within\")\n",
    "irwell_WB_IDs = list(set(list(joined_gdf.loc[joined_gdf.Unique_ID.isin(CaR_IDs)].EA_WB_ID.values)))\n",
    "irwell_WB_IDs\n",
    "\n",
    "# Get the Upper Irwell River network\n",
    "ui_gdf = gpd.read_file(f\"{data_path}/ui_watercourse.shp\")\n",
    "\n",
    "# Plot with Geopandas, specifying the column and color map\n",
    "ax = NFM_features_gdf.loc[NFM_features_gdf.EA_WB_ID.isin(irwell_WB_IDs)].plot(column=\"total_NFM_storage\", cmap=\"viridis\", alpha=0.75, legend=True, legend_kwds={\"label\":\"Total NFM storage (cubic m)\"}, zorder=1)\n",
    "ui_gdf.plot(ax=ax, zorder=2)\n",
    "joined_gdf.loc[joined_gdf.Unique_ID.isin(CaR_IDs)].plot(ax=ax, color=\"black\", zorder=3)\n",
    "\n",
    "\n",
    "# Remove x and y ticks and labels to make the graph neat.\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_title(\"Communities at risk in the Upper Irwell\\nNFM layers selected: \" + \", \".join(NFM_features_to_include))\n",
    "plt.savefig(f\"{results_path}/total_NFM_storage_and_CaR_map.png\", dpi=800, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "324ffb42-1313-4dd4-82be-e3536bf621d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "NVS5x-i5flm0"
   },
   "outputs": [],
   "source": [
    "# Read in the FEH data to find community at risk catchment area\n",
    "feh_data = pd.read_excel(f\"{data_path}/FEH_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfb52b8c-c32b-4476-8f6b-d8a48dbb17ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "VYFkl4fVNVvK"
   },
   "source": [
    "# 5. Functionality for calculating changes to communities at risk\n",
    "\n",
    "In this section we define a function the combines all of the datasets together to find GIA and benefit/cost ratios for the catchments from the Defra funding calculator.\n",
    "\n",
    "The DEFRA calculator is coded up as a seperate python module and imported as 'calculator'\n",
    "\n",
    "This function uses the following method:\n",
    "- Finds information related to the community of risk\n",
    "- calculates the %area of the water body that is associated with the community at risk catchment\n",
    "- Calculates the maximum potential NFM that could benefit that community\n",
    "- Calculates the design floods for that community from the JACOBS data\n",
    "- Calculates how much water needs to be stored to reduce the flood risk between categories\n",
    "- Compares that volume to the maximum storage available\n",
    "- Moves properties between flood risk categories according to the maximum reduction in flood risk available\n",
    "- Calculates the Grant in Aid (GIA) available using the DEFRA calculator and returns other metrics of interest such as the Benefit Cost Ratio.\n",
    "\n",
    "## Assumptions\n",
    "- Flood risk in a community can be well described by the FEH design event\n",
    "- NFM storage available is proportional to the fraction of the water body that the community's catchment area occupies.\n",
    "- No sliding scale of changing flood risk, either all properties move flood risk category or they don't.\n",
    "- The benefits calculation follows that currently used manually at the EA\n",
    "- Costs are uniform per cubic meter of storage\n",
    "\n",
    "## Running the code\n",
    "This section of code is the main functionality of the workbook, however, it is not actually used until we call it with details of specific communities at risk. Nothing should be changed in this code block, but it does need to be executed once per session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc737380-b190-41a7-96ef-0640237064c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the function that calculates GIA and other metrics of interest for each community\n",
    "def calc_gia_per_community(community_name, cc_factor, storage_cost, duration_of_benefits, fraction_of_max_NFM=1):\n",
    "  community_ids = [int(a) for a in CaR_ID_df.loc[CaR_ID_df.property_report_name == community_name].jacobs_storage_tool_ID.values[0].split(\"/\")]\n",
    "  community_X = int(joined_gdf.loc[joined_gdf.Unique_ID == community_ids[0]].SnappedX.values[0])\n",
    "  community_Y = int(joined_gdf.loc[joined_gdf.Unique_ID == community_ids[0]].SnappedY.values[0])\n",
    "  community_area = feh_data.loc[(feh_data.X == community_X)&(feh_data.Y == community_Y)].AREA.values[0]\n",
    "\n",
    "  wfd_max_storage = joined_gdf.loc[joined_gdf.Unique_ID.isin(community_ids)].total_NFM_storage.sum() # this will be found from the JBA map\n",
    "  wfd_area = joined_gdf.loc[joined_gdf.Unique_ID.isin(community_ids)].Area_km2.sum() #km2\n",
    "    \n",
    "  # Find the maximum NFM storage available to the community at risk\n",
    "  community_max_storage = (community_area/wfd_area) * wfd_max_storage * fraction_of_max_NFM\n",
    "\n",
    "  # Find the household data\n",
    "  POR = pd.read_excel(f\"{data_path}/{community_name}\" + \".xlsx\", sheet_name=\"RoFRS (excl. upper)\")\n",
    "\n",
    "  num_households_at_risk_today = pd.DataFrame({\n",
    "      \"deprivation_level\": [\"20% most deprived\", \"21% to 40% most deprived\", \"60% least deprived\"],\n",
    "      \"low_risk\": POR.iloc[1:4, 3].values,  # keep fixed (protected in worksheet)\n",
    "      \"moderate_risk\": POR.iloc[1:4, 4].values,  # three entries, one per deprivation level\n",
    "      \"intermediate_risk\": POR.iloc[1:4, 5].values,  # as above ...\n",
    "      \"significant_risk\": POR.iloc[1:4, 6].values,\n",
    "      \"very_significant_risk\": POR.iloc[1:4, 7].values,\n",
    "  })\n",
    "\n",
    "  num_households_at_risk_NFM = pd.DataFrame({\n",
    "      \"deprivation_level\": [\"20% most deprived\", \"21% to 40% most deprived\", \"60% least deprived\"],\n",
    "      \"low_risk\": POR.iloc[1:4, 3].values,  # keep fixed (protected in worksheet)\n",
    "      \"moderate_risk\": [0, 0, 0],  # create an empty dataframe for calculating future risk\n",
    "      \"intermediate_risk\": [0, 0, 0],  # as above ...\n",
    "      \"significant_risk\": [0, 0, 0],\n",
    "      \"very_significant_risk\": [0, 0, 0],\n",
    "  })\n",
    "\n",
    "\n",
    "  # Find the RP flows\n",
    "  RP5 = NFM_storage.loc[(NFM_storage.Unique_ID.isin(community_ids))&(NFM_storage.RP == \"RP5\")&(NFM_storage.timestep == 0.1)].Flow.sum()\n",
    "  RP20 = NFM_storage.loc[(NFM_storage.Unique_ID.isin(community_ids))&(NFM_storage.RP == \"RP20\")&(NFM_storage.timestep == 0.1)].Flow.sum()\n",
    "  RP50 = NFM_storage.loc[(NFM_storage.Unique_ID.isin(community_ids))&(NFM_storage.RP == \"RP50\")&(NFM_storage.timestep == 0.1)].Flow.sum()\n",
    "  RP100 = NFM_storage.loc[(NFM_storage.Unique_ID.isin(community_ids))&(NFM_storage.RP == \"RP100\")&(NFM_storage.timestep == 0.1)].Flow.sum()\n",
    "  RP200 = NFM_storage.loc[(NFM_storage.Unique_ID.isin(community_ids))&(NFM_storage.RP == \"RP200\")&(NFM_storage.timestep == 0.1)].Flow.sum()\n",
    "\n",
    "  # Find the flows\n",
    "\n",
    "  RP20_hydrograph = NFM_storage.loc[(NFM_storage.Unique_ID.isin(community_ids))&(NFM_storage.RP == \"RP20\")].groupby(\"timestep\")[\"QT\"].sum().to_numpy()\n",
    "  RP20_timesteps = np.sort(NFM_storage.loc[(NFM_storage.Unique_ID.isin(community_ids))&(NFM_storage.RP == \"RP20\")].timestep.unique())\n",
    "\n",
    "  RP50_hydrograph = NFM_storage.loc[(NFM_storage.Unique_ID.isin(community_ids))&(NFM_storage.RP == \"RP50\")].groupby(\"timestep\")[\"QT\"].sum().to_numpy()\n",
    "  RP50_timesteps = np.sort(NFM_storage.loc[(NFM_storage.Unique_ID.isin(community_ids))&(NFM_storage.RP == \"RP50\")].timestep.unique())\n",
    "\n",
    "  RP100_hydrograph = NFM_storage.loc[(NFM_storage.Unique_ID.isin(community_ids))&(NFM_storage.RP == \"RP100\")].groupby(\"timestep\")[\"QT\"].sum().to_numpy()\n",
    "  RP100_timesteps = np.sort(NFM_storage.loc[(NFM_storage.Unique_ID.isin(community_ids))&(NFM_storage.RP == \"RP100\")].timestep.unique())\n",
    "\n",
    "  RP200_hydrograph = NFM_storage.loc[(NFM_storage.Unique_ID.isin(community_ids))&(NFM_storage.RP == \"RP200\")].groupby(\"timestep\")[\"QT\"].sum().to_numpy()\n",
    "  RP200_timesteps = np.sort(NFM_storage.loc[(NFM_storage.Unique_ID.isin(community_ids))&(NFM_storage.RP == \"RP200\")].timestep.unique())\n",
    " \n",
    "\n",
    "  # Identify changes to the hydrograph based on available storage for different return periods\n",
    "\n",
    "  household_risk_changes = {}  # used to help with pv whole life benefit calculation\n",
    "\n",
    "  #RP5\n",
    "  RP5_20_vol = 0\n",
    "  for q in RP20_hydrograph:\n",
    "    if q > RP5:\n",
    "      RP5_20_vol += (q-RP5)*(0.1*3600)\n",
    "\n",
    "  RP5_50_vol = 0\n",
    "  for q in RP50_hydrograph:\n",
    "    if q > RP5:\n",
    "      RP5_50_vol += (q-RP5)*(0.1*3600)\n",
    "\n",
    "  RP5_100_vol = 0\n",
    "  for q in RP100_hydrograph:\n",
    "    if q > RP5:\n",
    "      RP5_100_vol += (q-RP5)*(0.1*3600)\n",
    "\n",
    "  RP5_200_vol = 0\n",
    "  for q in RP200_hydrograph:\n",
    "    if q > RP5:\n",
    "      RP5_200_vol += (q-RP5)*(0.1*3600)\n",
    "\n",
    "\n",
    "  #move RP5\n",
    "  #print(community_max_storage)\n",
    "  if community_max_storage > RP5_200_vol:\n",
    "    #print(\"move Very Significant Risk to Low Risk\")\n",
    "    num_households_at_risk_NFM.low_risk += num_households_at_risk_today.very_significant_risk\n",
    "    household_risk_changes[(\"very_significant_risk\", \"low_risk\")] = num_households_at_risk_today.very_significant_risk.sum()\n",
    "  elif community_max_storage > RP5_100_vol:\n",
    "    #print(\"move Very Significant Risk to Moderate Risk\")\n",
    "    num_households_at_risk_NFM.moderate_risk += num_households_at_risk_today.very_significant_risk\n",
    "    household_risk_changes[(\"very_significant_risk\", \"moderate_risk\")] = num_households_at_risk_today.very_significant_risk.sum()\n",
    "  elif community_max_storage > RP5_50_vol:\n",
    "    #print(\"move Very Significant Risk to Intermediate Risk\")\n",
    "    num_households_at_risk_NFM.intermediate_risk += num_households_at_risk_today.very_significant_risk\n",
    "    household_risk_changes[(\"very_significant_risk\", \"intermediate_risk\")] = num_households_at_risk_today.very_significant_risk.sum()\n",
    "  elif community_max_storage > RP5_20_vol:\n",
    "    #print(\"move Very Significant Risk to Significant Risk\")\n",
    "    num_households_at_risk_NFM.significant_risk += num_households_at_risk_today.very_significant_risk\n",
    "    household_risk_changes[(\"very_significant_risk\", \"significant_risk\")] = num_households_at_risk_today.very_significant_risk.sum()\n",
    "  else:\n",
    "    num_households_at_risk_NFM.very_significant_risk += num_households_at_risk_today.very_significant_risk\n",
    "    #print(\"No change (Very Significant Risk)\")\n",
    "\n",
    "  #RP20\n",
    "  RP20_50_vol = 0\n",
    "  for q in RP50_hydrograph:\n",
    "    if q > RP20:\n",
    "      RP20_50_vol += (q-RP20)*(0.1*3600)\n",
    "\n",
    "  RP20_100_vol = 0\n",
    "  for q in RP100_hydrograph:\n",
    "    if q > RP20:\n",
    "      RP20_100_vol += (q-RP20)*(0.1*3600)\n",
    "\n",
    "  RP20_200_vol = 0\n",
    "  for q in RP200_hydrograph:\n",
    "    if q > RP20:\n",
    "      RP20_200_vol += (q-RP20)*(0.1*3600)\n",
    "\n",
    "  \n",
    "    # move RP20\n",
    "  #print(community_max_storage)\n",
    "  if community_max_storage > RP20_200_vol:\n",
    "    #print(\"move Significant Risk to Low Risk\")\n",
    "    num_households_at_risk_NFM.low_risk += num_households_at_risk_today.significant_risk\n",
    "    household_risk_changes[(\"significant_risk\", \"low_risk\")] = num_households_at_risk_today.significant_risk.sum()\n",
    "  elif community_max_storage > RP20_100_vol:\n",
    "    #print(\"move Significant Risk to Moderate Risk\")\n",
    "    num_households_at_risk_NFM.moderate_risk += num_households_at_risk_today.significant_risk\n",
    "    household_risk_changes[(\"significant_risk\", \"moderate_risk\")] = num_households_at_risk_today.significant_risk.sum()\n",
    "  elif community_max_storage > RP20_50_vol:\n",
    "    #print(\"move Significant Risk to Intermediate Risk\")\n",
    "    num_households_at_risk_NFM.intermediate_risk += num_households_at_risk_today.significant_risk\n",
    "    household_risk_changes[(\"significant_risk\", \"intermediate_risk\")] = num_households_at_risk_today.significant_risk.sum()\n",
    "  else:\n",
    "    num_households_at_risk_NFM.significant_risk += num_households_at_risk_today.significant_risk\n",
    "    #print(\"No change (Significant Risk)\")\n",
    "\n",
    "\n",
    "  #RP50\n",
    "  RP50_100_vol = 0\n",
    "  for q in RP100_hydrograph:\n",
    "    if q > RP50:\n",
    "      RP50_100_vol += (q-RP50)*(0.1*3600)\n",
    "\n",
    "  RP50_200_vol = 0\n",
    "  for q in RP200_hydrograph:\n",
    "    if q > RP50:\n",
    "      RP50_200_vol += (q-RP50)*(0.1*3600)\n",
    "  \n",
    "\n",
    "\n",
    "  # move RP50\n",
    "  #print(community_max_storage)\n",
    "  if community_max_storage > RP50_200_vol:\n",
    "    #print(\"move Intermediate Risk to Low Risk\")\n",
    "    num_households_at_risk_NFM.low_risk += num_households_at_risk_today.intermediate_risk\n",
    "    household_risk_changes[(\"intermediate_risk\", \"low_risk\")] = num_households_at_risk_today.intermediate_risk.sum()\n",
    "  elif community_max_storage > RP50_100_vol:\n",
    "    #print(\"move Intermediate Risk to Moderate Risk\")\n",
    "    num_households_at_risk_NFM.moderate_risk += num_households_at_risk_today.intermediate_risk\n",
    "    household_risk_changes[(\"intermediate_risk\", \"moderate_risk\")] = num_households_at_risk_today.intermediate_risk.sum()\n",
    "  else:\n",
    "    num_households_at_risk_NFM.intermediate_risk += num_households_at_risk_today.intermediate_risk\n",
    "    #print(\"No change (Intermediate Risk)\")\n",
    "\n",
    "  #RP100\n",
    "\n",
    "  RP100_200_vol = 0\n",
    "  for q in RP200_hydrograph:\n",
    "    if q > RP100:\n",
    "      RP100_200_vol += (q-RP100)*(0.1*3600)\n",
    "  \n",
    "\n",
    "\n",
    "  # move RP100\n",
    "  #print(community_max_storage)\n",
    "  if community_max_storage > RP100_200_vol:\n",
    "    #print(\"move Moderate Risk to Low Risk\")\n",
    "    num_households_at_risk_NFM.low_risk += num_households_at_risk_today.moderate_risk\n",
    "    household_risk_changes[(\"moderate_risk\", \"low_risk\")] = num_households_at_risk_today.moderate_risk.sum()\n",
    "  else:\n",
    "    num_households_at_risk_NFM.moderate_risk += num_households_at_risk_today.moderate_risk\n",
    "    #print(\"No change (Moderate Risk)\")\n",
    "\n",
    "  pv_WLB_for_appraisal_period = calculator.calculate_pv_wlb(\n",
    "      household_risk_changes,\n",
    "      rofrs_damages_path=f\"{data_path}/{community_name}\" + \".xlsx\",  # path to community workbook containing \"RoFRS Damages\" worksheet\n",
    "      duration_of_benefits_DoB_period=duration_of_benefits\n",
    "  )\n",
    "\n",
    "\n",
    "  bcr, gia = calculator.calculate_gia(\n",
    "    community_max_storage*storage_cost,\n",
    "    pv_WLB_for_appraisal_period,\n",
    "    num_households_at_risk_today,\n",
    "    num_households_at_risk_NFM,\n",
    "    num_households_at_risk_2040_5b=num_households_at_risk_today,\n",
    "    num_households_at_risk_after_duration_of_benefits_5b=num_households_at_risk_NFM,\n",
    "    duration_of_benefits_DoB_period=duration_of_benefits\n",
    "    )\n",
    "\n",
    "\n",
    "  return(np.around(bcr, 2),\n",
    "         np.around(gia, 2),\n",
    "         np.around(gia*100/(community_max_storage*storage_cost), 2),\n",
    "         np.around(community_max_storage*storage_cost, 2),\n",
    "         np.around(pv_WLB_for_appraisal_period, 2),\n",
    "         num_households_at_risk_today,\n",
    "         num_households_at_risk_NFM,\n",
    "         RP5,\n",
    "         RP20,\n",
    "         RP50,\n",
    "         RP100,\n",
    "         RP200,\n",
    "         RP20_timesteps,\n",
    "         RP20_hydrograph,\n",
    "         RP50_timesteps,\n",
    "         RP50_hydrograph,\n",
    "         RP100_timesteps,\n",
    "         RP100_hydrograph,\n",
    "         RP200_timesteps,\n",
    "         RP200_hydrograph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b08daaa-fb1d-413a-b78a-c392238db89b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "lmH3vL7-4wVN"
   },
   "source": [
    "# 6. Calculating changes to an individual community\n",
    "\n",
    "Now we start getting into the code you can change! The code cells in this section investigate changes in flood risk to a single community at risk. They call the function in section 5 and produce a series of tables and figures\n",
    "\n",
    "## Running the code\n",
    "You can change the following lines of code:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "cc_factor = 1.26\n",
    "community_name = 'Woolfold'\n",
    "storage_cost = 20 #  per cubic m\n",
    "duration_of_benefits = 50\n",
    "\n",
    "```\n",
    "\n",
    "- cc_factor is the climate change factor you wish to explore. It is a simple multiple of the current flood risk. You can explore different uplift factors below. Note that it needs to be written as a scalar rather than a percentage (i.e an uplift of 26% is a scalar of 1.26)\n",
    "- community_name is the name of the community you wish to investigate. Ensure that you use the quote marks and spell the name exactly as it is in the files\n",
    "- storage_cost is the cost per cubic meter of storage.\n",
    "- duration_of_benefits is the duration of benefits to be used in the DEFRA calculator. The calculations are sensitive to the duration of benefits- the longer the benefits period the higher the Benefit Cost Ratio. As we dont have a figure for ongoing future costs, a rule of thumb is to use 50 years at an early stage, but refine it later. \n",
    "\n",
    "Simply edit the value after the equals sign and run the cells in this section\n",
    "\n",
    "\n",
    "## Climate uplift factors\n",
    "\n",
    "For reference (not currently used in the code) Irwell Management Catchment peak river flow allowances:\n",
    "\n",
    "Period | Central |\tHigher |\tUpper\n",
    "--- | --- |--- | ---\n",
    "2020s|\t12%\t|15%\t|24%\n",
    "2050s\t|19%\t|26%\t|43%\n",
    "2080s\t|35%|\t46%|\t75%\n",
    "\n",
    "From https://environment.data.gov.uk/hydrology/climate-change-allowances/river-flow?mgmtcatid=3042\n",
    "\n",
    "## Results\n",
    "The cells below outputs:\n",
    "- Values for the benefit cost ratio, GIA, costs and damages\n",
    "- A static hydrograph of the design storms from FEH for the baseline and with the cc uplift factor applied. This image can be copy and pasted into a report.\n",
    "- An interactive version of that graph if you wish to explore the data further\n",
    "- A plot of return period peak flows with and without climate uplift factors\n",
    "- A table of data showing households at risk today\n",
    "- A table of data showing households at risk under the NFM scheme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30384630-b300-4a44-b996-4c010bcae744",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Investigate changes to properties at risk in a given community\n",
    "cc_factor = 1.43\n",
    "community_name = \"Bacup_3\"\n",
    "storage_cost = 1 #  per cubic m\n",
    "duration_of_benefits = 50\n",
    "fraction_of_max_NFM_to_implement=1\n",
    "\n",
    "bcr, gia, pf_score, costs, damages, num_households_at_risk_today, num_households_at_risk_NFM, \\\n",
    "    RP5, RP20, RP50, RP100, RP200, RP20_timesteps, RP20_hydrograph, RP50_timesteps, \\\n",
    "    RP50_hydrograph, RP100_timesteps, RP100_hydrograph, RP200_timesteps, RP200_hydrograph = calc_gia_per_community(\n",
    "        community_name, cc_factor, storage_cost, duration_of_benefits, fraction_of_max_NFM = fraction_of_max_NFM_to_implement\n",
    "    )\n",
    "\n",
    "print(\"Community at Risk:\", community_name)\n",
    "print(\"NFM layers selected: \" + \", \".join(NFM_features_to_include))\n",
    "print(\"Fraction of Max NFM to implement:\", fraction_of_max_NFM_to_implement)\n",
    "print(\"Benefit Cost Ratio:\", bcr)\n",
    "print(\"Partnership Funding Score:\", pf_score, \"%\")\n",
    "print(\"GIA:\", gia)\n",
    "print(\"Costs: \", costs)\n",
    "print(\"Damages: \", damages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1ae88fb-5152-4452-aabc-8adab326b229",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "Ucf19WtyEUX0",
    "outputId": "1c76dad7-cf6a-41c9-91ac-444c867ccb05"
   },
   "outputs": [],
   "source": [
    "# For a single community\n",
    "\n",
    "# Plot the flows\n",
    "\n",
    "plt.hlines(y=RP5, xmin=0.1, xmax=10.2, color=\"black\", label=\"RP5\")\n",
    "\n",
    "plt.plot(RP20_timesteps, RP20_hydrograph, label=\"RP20\", color=\"#66c2a5\")\n",
    "plt.plot(RP20_timesteps, RP20_hydrograph*cc_factor, label=\"RP20_CC\", ls=\"--\", color=\"#66c2a5\")\n",
    "\n",
    "plt.plot(RP50_timesteps, RP50_hydrograph, label=\"RP50\", color=\"#fc8d62\")\n",
    "plt.plot(RP50_timesteps, RP50_hydrograph*cc_factor, label=\"RP50_CC\", ls=\"--\", color=\"#fc8d62\")\n",
    "\n",
    "plt.plot(RP100_timesteps, RP100_hydrograph, label=\"RP100\", color=\"#8da0cb\")\n",
    "plt.plot(RP100_timesteps, RP100_hydrograph*cc_factor, label=\"RP100_CC\", ls=\"--\", color=\"#8da0cb\")\n",
    "\n",
    "plt.plot(RP200_timesteps, RP200_hydrograph, label=\"RP200\", color=\"#e78ac3\")\n",
    "plt.plot(RP200_timesteps, RP200_hydrograph*cc_factor, label=\"RP200\", ls=\"--\", color=\"#e78ac3\")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Flow (cumecs)\")\n",
    "plt.xlabel(\"Time (hours)\")\n",
    "plt.title(\"Design flood events for \" + community_name)\n",
    "plt.savefig(f\"{results_path}/Design_flood_events_for_\" + community_name + \".png\", dpi=800, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd8eb25e-f9ee-4023-8436-f330c15c9953",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add RP5 horizontal line\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[min(RP20_timesteps), max(RP20_timesteps)],\n",
    "    y=[RP5, RP5],\n",
    "    mode=\"lines\",\n",
    "    line=dict(color=\"black\", width=2),\n",
    "    name=\"RP5\",\n",
    "    hoverinfo=\"skip\"  # No need for hover on static line\n",
    "))\n",
    "\n",
    "# Define colours\n",
    "colors = {\n",
    "    \"RP20\": \"#66c2a5\",\n",
    "    \"RP50\": \"#fc8d62\",\n",
    "    \"RP100\": \"#8da0cb\",\n",
    "    \"RP200\": \"#e78ac3\"\n",
    "}\n",
    "\n",
    "# Add hydrographs (original + climate change versions)\n",
    "for rp, timesteps, hydrograph, color in zip(\n",
    "    [\"RP20\", \"RP50\", \"RP100\", \"RP200\"],\n",
    "    [RP20_timesteps, RP50_timesteps, RP100_timesteps, RP200_timesteps],\n",
    "    [RP20_hydrograph, RP50_hydrograph, RP100_hydrograph, RP200_hydrograph],\n",
    "    colors.values()\n",
    "):\n",
    "    # Base hydrograph\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=timesteps,\n",
    "        y=hydrograph,\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=color, width=2),\n",
    "        name=rp,\n",
    "        hovertemplate=(\n",
    "            \"Time (hours): %{x}<br>\" +\n",
    "            \"Flow (cumecs): %{y}<br>\" +\n",
    "            \"Return Period: \" + rp\n",
    "        )\n",
    "    ))\n",
    "\n",
    "    # Climate change hydrograph (dashed)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=timesteps,\n",
    "        y=hydrograph * cc_factor,\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=color, width=2, dash=\"dash\"),\n",
    "        name=f\"{rp}_CC\",\n",
    "        hovertemplate=(\n",
    "            \"Time (hours): %{x}<br>\" +\n",
    "            \"Flow (cumecs): %{y}<br>\" +\n",
    "            \"Return Period: \" + f\"{rp}_CC\"\n",
    "        )\n",
    "    ))\n",
    "\n",
    "# Customise layout\n",
    "fig.update_layout(\n",
    "    title=f\"Design flood events for {community_name}\",\n",
    "    xaxis_title=\"Time (hours)\",\n",
    "    yaxis_title=\"Flow (cumecs)\",\n",
    "    legend_title=\"Return Periods\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5df81ce-6e6d-464e-8510-cd5cbf5785da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "QLU4yxCKyYyx",
    "outputId": "935d4b82-de9f-4f07-ac65-991c798d499c"
   },
   "outputs": [],
   "source": [
    "plt.plot([5, 20, 50, 100, 200], [RP5, RP20, RP50, RP100, RP200], label=\"baseline period\")\n",
    "plt.plot([5, 20, 50, 100, 200], np.array([RP5, RP20, RP50, RP100, RP200])*cc_factor, label=\"2040\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Return Period\")\n",
    "plt.ylabel(\"Flow (cumecs)\")\n",
    "plt.title(\"RP Flows for \" + community_name)\n",
    "plt.savefig(f\"{results_path}/Return_period_flows_for_\" + community_name + \".png\", dpi=800, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ecee7a7-f63a-43e2-ac5a-ca842433269a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "h4BNm-kob5Og",
    "outputId": "00ec3802-0bee-4ba0-bdb1-b4f2eb254e02"
   },
   "outputs": [],
   "source": [
    "# Show the number of households at risk today\n",
    "\n",
    "print(\"Number of households at risk today in \" + community_name)\n",
    "num_households_at_risk_today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a126a6d9-5fd2-457c-ab1f-5b7ea9ca3768",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "kL_PgUGtz1SG",
    "outputId": "011adacd-2f65-4a4f-a35d-6719087b75c8"
   },
   "outputs": [],
   "source": [
    "# Show the number of households at risk under maximum NFM storage\n",
    "print(\"Number of households at risk under maximum NFM scenario in \" + community_name)\n",
    "print(\"NFM layers selected: \" + \", \".join(NFM_features_to_include))\n",
    "num_households_at_risk_NFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fe5c079-a4f7-473e-bff1-9feb23064fef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File name- inculdes the datetime stamp so that your files don\"t get overwritten\n",
    "file_name = f\"{results_path}/households_risk_report\" + community_name + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")+ \".csv\"\n",
    "\n",
    "# Writing to CSV\n",
    "with open(file_name, \"w\") as f:\n",
    "    f.write(\"Community at Risk:\" + community_name + \"\\n\")\n",
    "    f.write(\"NFM layers selected: \" + \", \".join(NFM_features_to_include) + \"\\n\")\n",
    "    f.write(\"Fraction of Max NFM to implement: \" + str(fraction_of_max_NFM_to_implement) + \"\\n\")\n",
    "    f.write(\"Climate Change Factor: \" + str(cc_factor) + \"\\n\")\n",
    "    f.write(\"Storage cost: \" +  str(storage_cost) + \" per cubic m\" + \"\\n\")\n",
    "    f.write(\"Duration of benefits: \" + str(duration_of_benefits) + \"\\n\")\n",
    "    f.write(\"Benefit Cost Ratio: \" + str(bcr) + \"\\n\")\n",
    "    f.write(\"Partnership Funding Score: \" + str(pf_score) + \"%\" + \"\\n\")\n",
    "    f.write(\"GIA: \" + str(gia) + \"\\n\")\n",
    "    f.write(\"Costs: \" + str(costs) + \"\\n\")\n",
    "    f.write(\"Damages: \" + str(damages) + \"\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Number of households at risk today in {community_name}\\n\")\n",
    "num_households_at_risk_today.to_csv(file_name, mode=\"a\", index=False)\n",
    "\n",
    "with open(file_name, \"a\") as f:\n",
    "    f.write(f\"\\nNumber of households at risk under maximum NFM scenario in {community_name}\\n\")\n",
    "    f.write(f\"NFM layers selected: {', '.join(NFM_features_to_include)}\\n\")\n",
    "num_households_at_risk_NFM.to_csv(file_name, mode=\"a\", index=False)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7a999f1-4aed-4cf4-be82-f49a4d35a22b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for community_name in CaR_ID_df.property_report_name.values:\n",
    "    \n",
    "    # Investigate changes to properties at risk in a given community\n",
    "    cc_factor = 1.43\n",
    "    storage_cost = 1 #  per cubic m\n",
    "    duration_of_benefits = 50\n",
    "    fraction_of_max_NFM_to_implement=1\n",
    "    \n",
    "    bcr, gia, pf_score, costs, damages, num_households_at_risk_today, num_households_at_risk_NFM, \\\n",
    "        RP5, RP20, RP50, RP100, RP200, RP20_timesteps, RP20_hydrograph, RP50_timesteps, \\\n",
    "        RP50_hydrograph, RP100_timesteps, RP100_hydrograph, RP200_timesteps, RP200_hydrograph = calc_gia_per_community(\n",
    "            community_name, cc_factor, storage_cost, duration_of_benefits, fraction_of_max_NFM = fraction_of_max_NFM_to_implement\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # Plot the flows\n",
    "    \n",
    "    plt.hlines(y=RP5, xmin=0.1, xmax=10.2, color=\"black\", label=\"RP5\")\n",
    "    \n",
    "    plt.plot(RP20_timesteps, RP20_hydrograph, label=\"RP20\", color=\"#66c2a5\")\n",
    "    plt.plot(RP20_timesteps, RP20_hydrograph*cc_factor, label=\"RP20_CC\", ls=\"--\", color=\"#66c2a5\")\n",
    "    \n",
    "    plt.plot(RP50_timesteps, RP50_hydrograph, label=\"RP50\", color=\"#fc8d62\")\n",
    "    plt.plot(RP50_timesteps, RP50_hydrograph*cc_factor, label=\"RP50_CC\", ls=\"--\", color=\"#fc8d62\")\n",
    "    \n",
    "    plt.plot(RP100_timesteps, RP100_hydrograph, label=\"RP100\", color=\"#8da0cb\")\n",
    "    plt.plot(RP100_timesteps, RP100_hydrograph*cc_factor, label=\"RP100_CC\", ls=\"--\", color=\"#8da0cb\")\n",
    "    \n",
    "    plt.plot(RP200_timesteps, RP200_hydrograph, label=\"RP200\", color=\"#e78ac3\")\n",
    "    plt.plot(RP200_timesteps, RP200_hydrograph*cc_factor, label=\"RP200\", ls=\"--\", color=\"#e78ac3\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.ylabel(\"Flow (cumecs)\")\n",
    "    plt.xlabel(\"Time (hours)\")\n",
    "    plt.title(\"Design flood events for \" + community_name)\n",
    "    plt.savefig(f\"{results_path}/Design_flood_events_for_\" + community_name + \".png\", dpi=800, bbox_inches=\"tight\")\n",
    "    \n",
    "    plt.clf()\n",
    "    \n",
    "    plt.plot([5, 20, 50, 100, 200], [RP5, RP20, RP50, RP100, RP200], label=\"baseline period\")\n",
    "    plt.plot([5, 20, 50, 100, 200], np.array([RP5, RP20, RP50, RP100, RP200])*cc_factor, label=\"2040\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Return Period\")\n",
    "    plt.ylabel(\"Flow (cumecs)\")\n",
    "    plt.title(\"RP Flows for \" + community_name)\n",
    "    plt.savefig(f\"{results_path}/Return_period_flows_for_\" + community_name + \".png\", dpi=800, bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "    # File name\n",
    "    file_name = f\"{results_path}/households_risk_report\" + community_name + \".csv\"\n",
    "    \n",
    "    # Writing to CSV\n",
    "    with open(file_name, \"w\") as f:\n",
    "        f.write(\"Community at Risk:\" + community_name + \"\\n\")\n",
    "        f.write(\"NFM layers selected: \" + \", \".join(NFM_features_to_include) + \"\\n\")\n",
    "        f.write(\"Fraction of Max NFM to implement: \" + str(fraction_of_max_NFM_to_implement) + \"\\n\")\n",
    "        f.write(\"Climate Change Factor: \" + str(cc_factor) + \"\\n\")\n",
    "        f.write(\"Storage cost: \" +  str(storage_cost) + \" per cubic m\" + \"\\n\")\n",
    "        f.write(\"Duration of benefits: \" + str(duration_of_benefits) + \"\\n\")\n",
    "        f.write(\"Benefit Cost Ratio: \" + str(bcr) + \"\\n\")\n",
    "        f.write(\"Partnership Funding Score: \" + str(pf_score) + \"%\" + \"\\n\")\n",
    "        f.write(\"GIA: \" + str(gia) + \"\\n\")\n",
    "        f.write(\"Costs: \" + str(costs) + \"\\n\")\n",
    "        f.write(\"Damages: \" + str(damages) + \"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(f\"Number of households at risk today in {community_name}\\n\")\n",
    "    num_households_at_risk_today.to_csv(file_name, mode=\"a\", index=False)\n",
    "    \n",
    "    with open(file_name, \"a\") as f:\n",
    "        f.write(f\"\\nNumber of households at risk under maximum NFM scenario in {community_name}\\n\")\n",
    "        f.write(f\"NFM layers selected: {', '.join(NFM_features_to_include)}\\n\")\n",
    "    num_households_at_risk_NFM.to_csv(file_name, mode=\"a\", index=False)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d009104e-75d1-4f37-b9e8-cdaa8047b0f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Single community optimisation of NFM\n",
    "\n",
    "We can also investigate changing the fraction of the maximum available NFM to be implemented in a project to see if we can achieve better cost benefit ratios. \n",
    "\n",
    "Here we have set up the same code as before, but now we increment the fraction of the maximum available NFM to use to see if we can get a better cost benefit ratio using less NFM. \n",
    "\n",
    "This code block can run very slowly if we ask it to try lots of different fractions. If we ask it to simulate 100 increments (1% of max NFM, 2% of max NFM, 3% of max NFM etc. up to 100% max NFM) that will take ten times as long as checking 10 increments (10% of max NFM, 20% max NFM, 30% of max NFM etc.) You can change the line of code that controls this. Use:\n",
    "\n",
    "```fractions = np.linspace(0.01, 1, 100)``` for 100 increments or\n",
    "\n",
    "```fractions = np.linspace(0.1, 1, 10)``` for 10 increments\n",
    "\n",
    "The plot below shows how the benefit cost ratio changes with % max NFM implemented.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7c39eac-910b-48f7-8f3d-972b186c7315",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Investigate changes to properties at risk in a given community\n",
    "cc_factor = 1.43\n",
    "community_name = \"Bacup_3\"\n",
    "storage_cost = 1 #  per cubic m\n",
    "duration_of_benefits = 50\n",
    "\n",
    "\n",
    "# fractions = np.linspace(0.01, 1, 100) # Use these values if you want to have a very high resolution optimisation. This will try 100 different NFM fractions\n",
    "fractions = np.linspace(0.1, 1, 10) # This will try 10 different NFM fractions\n",
    "bcr_list = []\n",
    "\n",
    "for f in fractions:\n",
    "    bcr, gia, pf_score, costs, damages, num_households_at_risk_today, num_households_at_risk_NFM, \\\n",
    "        RP5, RP20, RP50, RP100, RP200, RP20_timesteps, RP20_hydrograph, RP50_timesteps, \\\n",
    "        RP50_hydrograph, RP100_timesteps, RP100_hydrograph, RP200_timesteps, RP200_hydrograph = calc_gia_per_community(\n",
    "            community_name, cc_factor, storage_cost, duration_of_benefits, fraction_of_max_NFM=f)\n",
    "\n",
    "    bcr_list.append(bcr)\n",
    "\n",
    "optimise_catch_df = pd.DataFrame({\"Fraction of Max NFM\": fractions, \"Benefit cost ratio\":bcr_list})\n",
    "\n",
    "filename = f\"{results_path}/optimised_NFM_fraction_for_\" + community_name + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")+ \".csv\"\n",
    "\n",
    "# Construct the header text\n",
    "header_text = (\n",
    "    f\"Incremental implementation of NFM in {community_name}\\n\"\n",
    "    f\"NFM layers selected: {', '.join(NFM_features_to_include)}\\n\"\n",
    "    f\"Storage cost: {storage_cost} per cubic m\\n\"\n",
    "    f\"Duration of benefits: {duration_of_benefits} years\\n\"\n",
    "    f\"Maximum NFM storage available: {np.around(costs / storage_cost)} cubic m\\n\"\n",
    ")\n",
    "\n",
    "# Write header to file\n",
    "with open(filename, \"w\") as f:\n",
    "    f.write(header_text + \"\\n\")  # Write header and add a blank line\n",
    "\n",
    "# Append DataFrame to the same file\n",
    "optimise_catch_df.to_csv(filename, mode=\"a\", index=False, float_format=\"%.2f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f0aa9de-e07d-44fb-9f2d-05f493c47bb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(fractions, bcr_list)\n",
    "plt.xlabel(\"fraction of max NFM used\")\n",
    "plt.ylabel(\"Cost benefit Ratio\")\n",
    "plt.title(header_text)\n",
    "plt.savefig(f\"{results_path}/optimised_NFM_fraction_for_\" + community_name + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")+ \".png\", dpi=800, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4fae239-ab9d-4f71-a4a6-a785aaf61f3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "dbfMgQTT8pgL"
   },
   "source": [
    "# 7. Calculating funding information for the whole of the Upper Irwell\n",
    "\n",
    "This section calculates the same information for every community in the Upper Irwell and provides summary maps and tables of data rather than individual community hydrographs and property information.\n",
    "\n",
    "## Running the code\n",
    "You can change the following lines of code:\n",
    "\n",
    "```\n",
    "cc_factor = 1.26\n",
    "storage_cost = 20 #  per cubic m\n",
    "duration_of_benefits = 50\n",
    "\n",
    "```\n",
    "\n",
    "- cc_factor is the climate change factor you wish to explore. It is a simple multiple of the current flood risk. You can explore different uplift factors below. Note that it needs to be written as a scalar rather than a percentage (i.e an uplift of 26% is a scalar of 1.26)\n",
    "- storage_cost is the cost per cubic meter of storage.\n",
    "- duration_of_benefits is the duration of benefits to be used in the DEFRA calculator.\n",
    "\n",
    "Simply edit the value after the equals sign and run the cells in this section\n",
    "\n",
    "## Results\n",
    "This section produces:\n",
    "- A static map of communities coloured by the benefit cost ratio\n",
    "- A table of communities prioritied by benefit cost ratio, sorted from highest BCR to lowest.\n",
    "- An interactive map of communities coloured by the benefit cost ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1213a43e-5431-4e16-9886-2cae3c09b55c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#For multiple communities\n",
    "# Lines to change\n",
    "cc_factor = 1.26\n",
    "storage_cost = 1 #  per cubic m\n",
    "duration_of_benefits = 50\n",
    "\n",
    "# Create a dataframe to store the results in\n",
    "prioritisation_df = pd.DataFrame({\"community_name\":[], \"Unique_ID\":[], \"gia\":[], \"bcr\":[], \"PF_score\":[], \"costs\":[], \"damages\":[]})\n",
    "ticker = 0\n",
    "\n",
    "#Loop through every community in the Upper Irwell\n",
    "for community_name in CaR_ID_df.property_report_name.values:\n",
    "  bcr, gia, pf_score, costs, damages, num_households_at_risk_today, num_households_at_risk_NFM, RP5, RP20, RP50, RP100, RP200, RP20_timesteps, RP20_hydrograph, RP50_timesteps, RP50_hydrograph, RP100_timesteps, RP100_hydrograph, RP200_timesteps, RP200_hydrograph = calc_gia_per_community(community_name, cc_factor, storage_cost, duration_of_benefits)\n",
    "  community_id = int(CaR_ID_df.loc[CaR_ID_df.property_report_name == community_name].jacobs_storage_tool_ID.values[0].split(\"/\")[0])\n",
    "  prioritisation_df.loc[ticker] = [community_name, community_id, gia, bcr, pf_score, costs, damages]\n",
    "  ticker += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c81d1625-7aab-4fa8-842c-5874ddd58ab5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join the Jacobs and JBA data\n",
    "\n",
    "merged_gdf = pd.merge(joined_gdf, prioritisation_df, on=\"Unique_ID\", how=\"inner\")\n",
    "irwell_WB_IDs = list(set(list(joined_gdf.loc[joined_gdf.Unique_ID.isin(CaR_IDs)].EA_WB_ID.values)))\n",
    "irwell_WB_IDs\n",
    "\n",
    "# Plot with Geopandas, specifying the column and color map\n",
    "ax = NFM_features_gdf.loc[NFM_features_gdf.EA_WB_ID.isin(irwell_WB_IDs)].plot(column=\"total_NFM_storage\", cmap=\"viridis\", alpha=0.75, legend=True, legend_kwds={\"label\":\"Total NFM storage (cubic m)\"})\n",
    "merged_gdf.loc[merged_gdf.Unique_ID.isin(CaR_IDs)].plot(\n",
    "    ax=ax,\n",
    "    column=\"bcr\",\n",
    "    cmap=\"PiYG\",  # Choose a suitable color map\n",
    "    markersize=10,\n",
    "    legend=True,\n",
    "    legend_kwds={\"label\": \"Benefit Cost Ratio\"}\n",
    ")\n",
    "\n",
    "header_text = (\n",
    "    f\"Communities at risk in the Upper Irwell\\n\"\n",
    "    f\"NFM layers selected: {', '.join(map(str, NFM_features_to_include))}\\n\"\n",
    "    f\"Storage cost: {storage_cost} per cubic m\\n\"\n",
    "    f\"Duration of benefits: {duration_of_benefits} years\\n\")\n",
    "# Remove x and y ticks and labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_title(header_text)\n",
    "plt.savefig(f\"{results_path}/BCR_map\" + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + \".png\", dpi=800, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ced36b97-04f0-421f-b9be-5987bb94f186",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Show the prioritised list of communities\n",
    "# If you wish to see all of the rows, remove .head(20) from the line of code below.\n",
    "print(\"Communities at risk in the Upper Irwell\\nNFM layers selected: \" + \", \".join(NFM_features_to_include))\n",
    "prioritisation_df.sort_values(by='bcr', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb81d8c0-07da-49f6-8bef-e84e17785a35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File name\n",
    "file_name = f\"{results_path}/prioritised_CaR\" + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + \".csv\"\n",
    "\n",
    "# Writing to CSV\n",
    "with open(file_name, \"w\") as f:\n",
    "    f.write(header_text)\n",
    "prioritisation_df.sort_values(by=\"bcr\", ascending=False).to_csv(file_name, mode=\"a\", index=False)\n",
    "\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a47ec604-d149-418f-a41d-0179d34c3539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reproject the data to WGS84 (EPSG:4326)\n",
    "gdf_wgs84 = NFM_features_gdf.to_crs(epsg=4326)\n",
    "merged_gdf_wgs84 = merged_gdf.to_crs(epsg=4326)\n",
    "\n",
    "# Create base map centered on reprojected data\n",
    "m = folium.Map(\n",
    "    location=[gdf_wgs84.geometry.centroid.y.mean(), gdf_wgs84.geometry.centroid.x.mean()],\n",
    "    zoom_start=10,\n",
    "    tiles='OpenStreetMap'\n",
    ")\n",
    "\n",
    "# Create colour maps\n",
    "storage_colourmap = cm.LinearColormap(\n",
    "    colors=[mpl_colors.rgb2hex(mpl_cm.viridis(i)) for i in range(256)],  # Use Viridis colourmap\n",
    "    vmin=gdf_wgs84['total_NFM_storage'].min(),\n",
    "    vmax=gdf_wgs84['total_NFM_storage'].max(),\n",
    "    caption='Total NFM Storage'\n",
    ")\n",
    "\n",
    "# Add polygons (storage data)\n",
    "folium.GeoJson(\n",
    "    gdf_wgs84,\n",
    "    style_function=lambda x: {\n",
    "        'fillColor': storage_colourmap(x['properties']['total_NFM_storage']),\n",
    "        'color': 'black',\n",
    "        'weight': 0.5,\n",
    "        'fillOpacity': 0.75\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(fields=['total_NFM_storage'], aliases=['Storage: '])\n",
    ").add_to(m)\n",
    "\n",
    "# Normalise the bcr values for marker sizing\n",
    "bcr_min = merged_gdf_wgs84['bcr'].min()\n",
    "bcr_max = merged_gdf_wgs84['bcr'].max()\n",
    "\n",
    "# Define marker size scaling function\n",
    "def scale_bcr(value, min_size=3, max_size=25):\n",
    "    \"\"\"Scale the bcr values to a range of marker sizes.\"\"\"\n",
    "    return min_size + (value - bcr_min) / (bcr_max - bcr_min) * (max_size - min_size)\n",
    "\n",
    "# Add markers with proportional sizes\n",
    "for _, row in merged_gdf_wgs84.iterrows():\n",
    "    size = scale_bcr(row['bcr'])  # Scale the marker size based on bcr\n",
    "    folium.CircleMarker(\n",
    "        location=[row.geometry.centroid.y, row.geometry.centroid.x],\n",
    "        radius=size,  # Set radius based on scaled bcr\n",
    "        color='#000000',\n",
    "        fill=True,\n",
    "        fill_color='#252525',\n",
    "        fill_opacity=0.8,\n",
    "        popup=f\"BCR: {row['bcr']}<br>Community: {row['community_name']}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add polygon colourmap to map\n",
    "storage_colourmap.add_to(m)\n",
    "\n",
    "# Display map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caf51b4f-e4ca-486c-a859-867c0eda533d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Prioritisation with optimisation\n",
    "\n",
    "Here we use the optimal fraction of NFM for each community at risk and rank the potential projects as above to see if we can achieve better cost benefit ratios. \n",
    "\n",
    "Here we have set up the same code as before, but now we increment the fraction of the maximum available NFM to use to see if we can get a better cost benefit ratio using less NFM. \n",
    "\n",
    "This code block can run very slowly as we are asking it to try lots of different fractions for EVERY CaR. If we ask it to simulate 100 increments (1% of max NFM, 2% of max NFM, 3% of max NFM etc. up to 100% max NFM) that will take ten times as long as checking 10 increments (10% of max NFM, 20% max NFM, 30% of max NFM etc.) You can change the line of code that controls this. Use:\n",
    "\n",
    "```fractions = np.linspace(0.01, 1, 100)``` for 100 increments or\n",
    "\n",
    "```fractions = np.linspace(0.1, 1, 10)``` for 10 increments\n",
    "\n",
    "The table below shows prioritisation outputs for both the optimal fraction of max NFM implemented and the max NFM implemented. The map shows the prioiritsation as above but for the optimal CBR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dc035f1-b72a-4345-9195-020bb3194ddf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#For multiple communities\n",
    "# Lines to change\n",
    "cc_factor = 1.26\n",
    "storage_cost = 1 #  per cubic m\n",
    "duration_of_benefits = 50\n",
    "\n",
    "header_text = (\n",
    "    f\"Communities at risk in the Upper Irwell, optimised NFM fraction\\n\"\n",
    "    f\"NFM layers selected: {', '.join(NFM_features_to_include)}\\n\"\n",
    "    f\"Storage cost: {storage_cost} per cubic m\\n\"\n",
    "    f\"Duration of benefits: {duration_of_benefits} years\\n\")\n",
    "\n",
    "# Create a dataframe to store the results in\n",
    "prioritisation_df = pd.DataFrame({\"community_name\":[], \"Unique_ID\":[], \"Optimal_NFM_Fraction\":[], \"gia_optimal\":[], \"bcr_optimal\":[], \"PF_score_optimal\":[], \"costs_optimal\":[], \"damages_optimal\":[], \"gia_max\":[], \"bcr_max\":[], \"PF_score_max\":[], \"costs_max\":[], \"damages_max\":[]})\n",
    "ticker = 0\n",
    "\n",
    "#Loop through every community in the Upper Irwell\n",
    "for community_name in CaR_ID_df.property_report_name.values:\n",
    "  #fractions = np.linspace(0.05, 1, 20)\n",
    "  fractions = np.linspace(0.1, 1, 10)\n",
    "  gia_list = []\n",
    "  bcr_list = []\n",
    "  pf_list = []\n",
    "  costs_list = []\n",
    "  damages_list = []\n",
    "\n",
    "  for f in fractions:\n",
    "    bcr, gia, pf_score, costs, damages, num_households_at_risk_today, num_households_at_risk_NFM, RP5, RP20, RP50, RP100, RP200, RP20_timesteps, RP20_hydrograph, RP50_timesteps, RP50_hydrograph, RP100_timesteps, RP100_hydrograph, RP200_timesteps, RP200_hydrograph = calc_gia_per_community(community_name, cc_factor, storage_cost, duration_of_benefits, fraction_of_max_NFM=f)\n",
    "    community_id = int(CaR_ID_df.loc[CaR_ID_df.property_report_name == community_name].jacobs_storage_tool_ID.values[0].split(\"/\")[0])\n",
    "    gia_list.append(gia)\n",
    "    bcr_list.append(bcr)\n",
    "    pf_list.append(pf_score)\n",
    "    costs_list.append(costs)\n",
    "    damages_list.append(damages)\n",
    "      \n",
    "  i = np.argmax(np.array(bcr_list))\n",
    "  prioritisation_df.loc[ticker] = [community_name, community_id, fractions[i], gia_list[i], bcr_list[i], pf_list[i], costs_list[i], damages_list[i], gia_list[-1], bcr_list[-1], pf_list[-1], costs_list[-1], damages_list[-1]]\n",
    "  ticker += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3be7eecc-3cfc-4ed1-9489-a757c15b4169",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(header_text)\n",
    "prioritisation_df.sort_values(by=\"bcr_optimal\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9aa5b1ff-8d48-4e21-bfc5-e62c3838dd46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File name\n",
    "file_name = f\"{results_path}/Optimised_prioritised_CaR.csv\"\n",
    "\n",
    "# Writing to CSV\n",
    "with open(file_name, \"w\") as f:\n",
    "    f.write(header_text)\n",
    "prioritisation_df.sort_values(by=\"bcr_optimal\", ascending=False).to_csv(file_name, mode=\"a\", index=False)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "573753cc-f37c-4fcc-a197-e63f2a2f2b94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join the Jacobs and JBA data\n",
    "merged_gdf = pd.merge(joined_gdf, prioritisation_df, on=\"Unique_ID\", how=\"inner\")\n",
    "irwell_WB_IDs = list(set(list(joined_gdf.loc[joined_gdf.Unique_ID.isin(CaR_IDs)].EA_WB_ID.values)))\n",
    "irwell_WB_IDs\n",
    "\n",
    "# Plot with Geopandas, specifying the column and color map\n",
    "ax = NFM_features_gdf.loc[NFM_features_gdf.EA_WB_ID.isin(irwell_WB_IDs)].plot(column=\"total_NFM_storage\", cmap=\"viridis\", alpha=0.75, legend=True, legend_kwds={\"label\":\"Total NFM storage (cubic m)\"})\n",
    "merged_gdf.loc[merged_gdf.Unique_ID.isin(CaR_IDs)].plot(\n",
    "    ax=ax,\n",
    "    column=\"bcr_optimal\",\n",
    "    cmap=\"PiYG\",  # Choose a suitable color map\n",
    "    markersize=10,\n",
    "    legend=True,\n",
    "    legend_kwds={\"label\": \"Benefit Cost Ratio\"}\n",
    ")\n",
    "\n",
    "# Remove x and y ticks and labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_title(header_text)\n",
    "plt.savefig(f\"{results_path}/BCR_optimised_map\" + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + \".png\", dpi=800, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5239298702256656,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "irwell_investment_tool",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
